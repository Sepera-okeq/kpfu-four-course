# Теория

## Содержание
- [Тема 0. Основы параллельного программирования](#тема-0-основы-параллельного-программирования)
  - [Для чего нужно параллельное программирование?](#для-чего-нужно-параллельное-программирование)
  - [Закон Мура и его ограничения](#закон-мура-и-его-ограничения)
  - [Подход параллельного программирования](#подход-параллельного-программирования)
- [Тема 1. Классификация параллельных компьютеров](#тема-1-классификация-параллельных-компьютеров)
  - [Классификация по Флинну](#классификация-по-флинну)
  - [Разделение категории MIMD](#разделение-категории-mimd)
  - [Классификация по типу памяти (Джонсона)](#классификация-по-типу-памяти-джонсона)
  - [Инструменты создания параллельных программ](#инструменты-создания-параллельных-программ)
  - [Модели RAM и PRAM](#модели-ram-и-pram)
  - [Чаво](#чаво)
- [Тема 2: OpenMP - Многопоточность для C/C++](#тема-2-openmp---многопоточность-для-cc)
  - [Основные понятия](#основные-понятия)
  - [OpenMP в Visual Studio](#openmp-в-visual-studio)
  - [Компоненты OpenMP](#компоненты-openmp)
  - [Блокировки (мьютексы)](#блокировки-мьютексы)
  - [Эффективное использование OpenMP](#эффективное-использование-openmp)
  - [Автоматическое распараллеливание](#автоматическое-распараллеливание)
  - [Резюме](#резюме)
- [Тема 3 - 4. MPI: Подробное руководство](#тема-3---4-mpi-подробное-руководство)
  - [Основные концепции и функции](#основные-концепции-и-функции)
- [Тема 5. Основы архитектуры ЭВМ и выполнения программ](#тема-5-основы-архитектуры-эвм-и-выполнения-программ)
  - [Архитектура компьютера (общая картина)](#архитектура-компьютера-общая-картина)
  - [Архитектуры компьютеров (по памяти)](#архитектуры-компьютеров-по-памяти)
  - [Регистры](#регистры)
  - [Выполнение программ (упрощенно)](#выполнение-программ-упрощенно)
  - [Цикл выполнения команд (упрощенно)](#цикл-выполнения-команд-упрощенно)
  - [Типы команд (упрощенно)](#типы-команд-упрощенно)
  - [Формат команд (упрощенно)](#формат-команд-упрощенно)
  - [Взаимодействие с памятью (пример)](#взаимодействие-с-памятью-пример)
  - [Хранение переменных](#хранение-переменных)
  - [Вызов функции и хранение локальных переменных](#вызов-функции-и-хранение-локальных-переменных)
  - [Хранение результатов выполнения](#хранение-результатов-выполнения)
  - [Организация памяти](#организация-памяти)
  - [Массивы и указатели](#массивы-и-указатели)
  - [Структуры и классы](#структуры-и-классы)
  - [Обращения к внешним устройствам](#обращения-к-внешним-устройствам)
  - [Резюме](#резюме-1)
- [Тема 6. Организация компьютера](#тема-6-организация-компьютера)
  - [О лекции](#о-лекции)
  - [Организация компьютера (общая картина)](#организация-компьютера-общая-картина)
  - [Архитектура и микроархитектура](#архитектура-и-микроархитектура)
  - [Методы повышения производительности ЦП](#методы-повышения-производительности-цп)
  - [Развитие микропрограммирования](#развитие-микропрограммирования)
  - [Производительность процессоров](#производительность-процессоров)
  - [Архитектуры процессоров](#архитектуры-процессоров)
  - [Улучшения микроархитектуры](#улучшения-микроархитектуры)
  - [Повышение производительности ЦП](#повышение-производительности-цп)
  - [Стадии выполнения команд](#стадии-выполнения-команд)
  - [Конвейерный процессор](#конвейерный-процессор)
  - [Характеристики конвейера](#характеристики-конвейера)
  - [Факторы, влияющие на производительность конвейера](#факторы-влияющие-на-производительность-конвейера)
  - [Краткие итоги](#краткие-итоги)
- [Тема 7. Кэш-память](#тема-7-кэш-память)
  - [О лекции](#о-лекции-1)
  - [Организация системы памяти](#организация-системы-памяти)
  - [Уровни кэша](#уровни-кэша)
  - [Виды кэша](#виды-кэша)
  - [Кэш-промах и кэш-попадание](#кэш-промах-и-кэш-попадание)
  - [Функции контроллера кэша](#функции-контроллера-кэша)
  - [Локализация (локальность)](#локализация-локальность)
  - [Организация работы кэш-памяти](#организация-работы-кэш-памяти)
  - [Типы кэш-памяти](#типы-кэш-памяти)
  - [Характеристики КП современных процессоров](#характеристики-кп-современных-процессоров)
  - [Предвыборка данных](#предвыборка-данных)
  - [Core i7 (пример организации кэша)](#core-i7-пример-организации-кэша)
  - [Использование особенностей КП для повышения производительности](#использование-особенностей-кп-для-повышения-производительности)
  - [Примеры](#примеры)
  - [False Sharing](#false-sharing)
  - [Резюме](#резюме-2)
- [Тема 8. Повышение производительности процессора](#тема-8-повышение-производительности-процессора)
  - [О лекции](#о-лекции-2)
  - [Архитектура и микроархитектура](#архитектура-и-микроархитектура-1)
  - [Методы повышения производительности ЦП](#методы-повышения-производительности-цп-1)
  - [Развитие микропрограммирования](#развитие-микропрограммирования-1)
  - [Производительность процессоров](#производительность-процессоров-1)
  - [Архитектуры процессоров](#архитектуры-процессоров-1)
  - [Улучшения микроархитектуры](#улучшения-микроархитектуры-1)
  - [Повышение производительности ЦП](#повышение-производительности-цп-1)
  - [Стадии выполнения команд](#стадии-выполнения-команд-1)
  - [Конвейерный процессор](#конвейерный-процессор-1)
  - [Характеристики конвейера](#характеристики-конвейера-1)
  - [Факторы, влияющие на производительность конвейера](#факторы-влияющие-на-производительность-конвейера-1)
  - [Прогнозирование переходов](#прогнозирование-переходов)
  - [Базовые блоки](#базовые-блоки)
  - [Спекулятивное исполнение](#спекулятивное-исполнение)
  - [Параллелизм на разных уровнях](#параллелизм-на-разных-уровнях)
  - [Внутрипроцессорный параллелизм](#внутрипроцессорный-параллелизм)
  - [VLIW (Very Long Instruction Word)](#vliw-very-long-instruction-word)
  - [Развитие архитектуры компьютеров](#развитие-архитектуры-компьютеров)
  - [Модель IA-64 – EPIC (Itanium)](#модель-ia-64--epic-itanium)
  - [Внутрипроцессорная многопоточность](#внутрипроцессорная-многопоточность)
  - [Однокристальные МП](#однокристальные-мп)
  - [Сопроцессоры](#сопроцессоры)
  - [Сети](#сети)
  - [GPU](#gpu)
  - [МП (SMP)](#мп-smp)
  - [МК](#мк)
  - [Гибридные системы](#гибридные-системы)
  - [Проектирование МК](#проектирование-мк)
  - [Категории МК](#категории-мк)
  - [IBM BlueGene](#ibm-bluegene)
  - [Кластер](#кластер)

## Тема 0. Основы параллельного программирования

**Для чего нужно параллельное программирование?**  
Параллельное программирование решает задачи, требующие высокой производительности, оно необходимо для:  

- моделирования сложных процессов в физике, химии, биологии и медицине;  
- исследований истории Вселенной;  
- разработки новых лекарств в фармацевтике;  
- проектирования летательных аппаратов;  
- анализа мировой экономики;  
- прогнозов в экономике и финансах.  

Эти области требуют сверхмощных вычислений, которые невозможно реализовать на традиционных устройствах без использования параллельной обработки.

---

**Закон Мура и его ограничения**  
В 1965 году Гордон Мур, сооснователь Intel, заметил: число транзисторов на кристалле удваивается каждые два года. Это приводило к росту производительности и снижению стоимости вычислительной техники, обеспечивая экспоненциальное развитие микроэлектроники.

Однако закон Мура со временем замедлился из-за таких ограничений:  

1. **Скорость света** — сигналы на кристалле не могут распространяться быстрее скорости света, что ограничивает скорость передачи данных.  
2. **Теплоотдача** — плотность транзисторов растет, увеличивается энергопотребление и тепловыделение, что приводит к проблемам охлаждения.  
3. **Квантовые эффекты** — при миниатюризации транзисторов до нанометрового уровня возникают явления, такие как туннелирование электронов. Это вызывает утечку тока, снижает надежность системы и ставит пределы дальнейшему снижению размеров компонентов.

Препятствия на пути к росту производительности создают необходимость поиска новых методов и технологий обработки данных.

---

**Подход параллельного программирования**  
Для преодоления ограничений традиционной микроэлектроники используются подходы параллельных вычислений:

1. **Параллельные компьютеры**  
   Современные системы вместо увеличения тактовой частоты используют множество процессоров, работающих одновременно. Это позволяет дробить задачу на подзадачи и выполнять их параллельно, ускоряя вычисления.  

2. **Многоядерные процессоры и графические ускорители (GPU)**  
   Архитектура с несколькими ядрами или специализированными блоками обработки данных стала стандартом. Это особенно важно для работы с большими данными, машинного обучения и других ресурсоемких процессов. GPU играют ключевую роль, выполняя множество операций одновременно.  

3. **Кластеры и суперкомпьютеры**  
   Параллельные компьютеры могут объединяться в кластеры — это системы, работающие как единое целое. Суперкомпьютеры состоят из десятков тысяч вычислительных узлов, связываемых с помощью высокоскоростных сетей. Такая структура обеспечивает эффективное распределение нагрузки между узлами для решения самых сложных задач.  

4. **Улучшение сетевых технологий**  
   Высокоскоростные соединения позволяют передавать данные между узлами параллельных систем с минимальными задержками, что критически важно для согласованной работы всего кластера.

---

## Тема 1. Классификация параллельных компьютеров

Для начала давайте разберемся с основной терминологией. **Поток данных или команд** — это последовательность задач (команд) или информации (данных), которые обрабатываются процессором. Потоки могут быть независимыми друг от друга, что позволяет разделить их на разные процессы или ядра.

---

#### Классификация по Флинну

Майкл Флинн предложил классификацию параллельных компьютеров, основываясь на количестве потоков команд (**I**) и потоков данных (**D**). Всего выделяют четыре типа:

1. **SISD** (Single Instruction, Single Data — одна команда, одни данные):  
   Обычный последовательный процессор. Например, процесс вычисляет \(a_1 + b_1\).  

2. **SIMD** (Single Instruction, Multiple Data — одна команда, несколько данных):  
   Одна команда выполняется сразу над несколькими наборами данных. Например, сразу вычисляется:  
   \[
   a_1 + b_1 \quad a_2 + b_2 \quad a_3 + b_3
   \]  
   Это часто используется в графических процессорах (GPU).  

3. **MISD** (Multiple Instruction, Single Data — несколько команд, одни данные):  
   Редко встречающийся тип, при котором один и тот же набор данных обрабатывается разными командами. Например, из одного значения \(a_1\):  
   \[
   a_1 + b_1, \quad a_1 - b_1, \quad a_1 * b_1
   \]  

4. **MIMD** (Multiple Instruction, Multiple Data — несколько команд, несколько данных):  
   Наиболее распространенный тип современных процессоров. Разные ядра выполняют разные команды на разных данных. Например:  
   \[
   a_1 + b_1, \quad a_2 - b_2, \quad a_3 * b_3
   \]

---

#### Разделение категории MIMD

В рамках MIMD можно выделить два типа:  
1. **Мультипроцессоры:** Все процессоры находятся в одной системе и подключены к общей памяти. Они работают на одном физическом устройстве.  
2. **Мультикомпьютеры:** Это сеть независимых узлов (компьютеров), каждый из которых имеет свою локальную память. Узлы общаются только через сеть.

---

#### Классификация по типу памяти (Джонсона)

Системы параллельных вычислений можно разделить на три типа в зависимости от способа хранения и доступа к памяти:  
1. **Общая память (Shared memory):**  
   - Несколько процессоров/ядер имеют доступ к одному набору памяти.  
   - Все процессоры могут работать с любой ячейкой памяти напрямую.  
   - Подключение осуществляется через шину или специальные коммутаторы.  

2. **Распределенная память (Distributed memory):**  
   - Каждый узел имеет собственную локальную память.  
   - Прямого доступа к памяти других узлов нет, данные передаются через сеть.  

3. **Гибридные архитектуры:**  
   - Сочетают оба типа памяти. Например, в кластерах суперкомпьютеров — узлы объединены через сеть (распределенная память), а внутри каждого узла процессоры используют общую память.

---

#### Инструменты создания параллельных программ

Для программирования под различные архитектуры используются специфические инструменты:  
- **Для общей памяти:** Используют многопоточное программирование с потоками (нитями), например, через **OpenMP**.  
- **Для распределенной памяти:** Узлы общаются друг с другом через обмен сообщениями с помощью **MPI (Message Passing Interface)**.

---

#### Модели RAM и PRAM

Чтобы анализировать производительность параллельных алгоритмов, используют идеализированные модели вычислительных систем:  
1. **RAM (Random Access Machine):**  
   - Состоит из процессора, памяти и системной шины (канала связи).  
   - Эта модель описывает обычный последовательный компьютер.  

2. **PRAM (Parallel Random Access Machine):**  
   - Устройство состоит из \(p\) процессоров.  
   - Управляющий блок передает команды всем процессорам.  
   - Все процессоры подключены к памяти через системную шину.  
   - Описывает идеальную параллельную систему, где отсутствуют конфликты доступа к памяти и задержки.

---

#### Чаво

1. **Есть разные типы параллельных компьютеров, которые работают с потоками команд и данных.**  
2. **Наиболее распространены архитектуры с общей памятью, распределенной памятью или их сочетания.**  
3. **Выбор инструментов программирования зависит от архитектуры: OpenMP для общей памяти и MPI для распределенной.**  
4. **RAM и PRAM – теоретические модели, помогающие анализировать производительность алгоритмов и проектировать параллельные системы.**

## Тема 2: OpenMP - Многопоточность для C/C++

OpenMP (Open Multi-Processing) - это API (интерфейс прикладного программирования), предназначенный для создания многопоточных приложений на языках C/C++ и Fortran в системах с общей памятью.  Он позволяет распараллеливать выполнение программы, используя возможности многоядерных процессоров.  В отличие от процессов, которые имеют собственную память, потоки внутри одного процесса разделяют общую память, что упрощает обмен данными между ними, но требует тщательной синхронизации.

**Основные понятия:**

* **Потоки:**  "Легковесные" единицы выполнения внутри процесса, разделяющие общую память.
* **Процессы:** "Тяжеловесные" единицы выполнения, имеющие собственную память.
* **Общая память:**  Память, доступная всем потокам внутри процесса.
* **Синхронизация:** Механизмы, обеспечивающие согласованный доступ потоков к общим ресурсам.

**OpenMP в Visual Studio:**

* **Версии:** OpenMP имеет несколько версий (2.0, ..., 5.0). В Visual Studio поддерживается OpenMP 2.0 (`_OPENMP=200203`).  В данном материале рассматривается версия 2.0.
* **Подключение:** Для использования OpenMP необходимо включить опцию компилятора `/openmp`.

**Компоненты OpenMP:**

* **Библиотеки функций:**  Функции для управления потоками (например, `omp_get_num_threads()`, `omp_get_thread_num()`).
* **Переменные окружения:**  Для настройки параметров OpenMP (например, `OMP_NUM_THREADS`, `OMP_NESTED`).
* **Директивы препроцессора:** Основной механизм распараллеливания кода. Начинаются с `#pragma omp`. 

**Пример "Hello, OpenMP!":**

```c++
#pragma omp parallel
{
    cout << "Hello, OpenMP\n";
}
```

**Директивы OpenMP:**

* **`#pragma omp parallel`:** Создает группу потоков, каждый из которых выполнит следующий за директивой блок кода.
* **Область действия директив:** Директивы действуют на следующий за ними структурный блок кода (одна команда или блок, заключенный в фигурные скобки `{}`).
* **Функции `omp_get_num_threads()` и `omp_get_thread_num()`:**  Возвращают количество потоков в группе и номер текущего потока соответственно. Внутри параллельного блока возвращают корректные значения, вне его - 1 и 0 соответственно.

**Пример использования номера потока:**

```c++
#pragma omp parallel
{
    int myid = omp_get_thread_num();
    if (myid == 0) {
        // Действия для главного потока
    } else {
        // Действия для остальных потоков
    }
}
```

**Обработка директив:**

* Директивы обрабатываются препроцессором.
* Компилятор обнаруживает синтаксические ошибки в директивах, но не логические ошибки распараллеливания.

**Схема программирования в OpenMP:**

Программа состоит из последовательных и параллельных областей.  Параллельные области создаются с помощью директив OpenMP.

**Создание и завершение потоков:**

* Изначально существует только главный поток (main thread) с номером 0.
* Директива `parallel` создает группу потоков.
* После завершения параллельной области выполнение продолжает только главный поток.

**Взаимодействие потоков:**

* Потоки могут быть независимыми или взаимодействующими.
* Взаимодействующие потоки обмениваются данными через общую память.
* Синхронизация необходима для предотвращения гонок данных (data races).

**Синтаксис директив:**

```
#pragma omp директива [команда [команда] ... ]
```


**Основные директивы и команды:**

* **`parallel`:**  Создает группу потоков.  Имеет ряд команд:
    * **`if(expr)`:**  Параллельное выполнение, только если `expr` истинно.
    * **`num_threads(int)`:**  Задает количество потоков.
    * **`shared(var1, ...)`:**  Перечисленные переменные являются общими для всех потоков. Необходимо иницилизация переменных!
    * **`private(var1, ...)`:**  Создает локальную копию переменной для каждого потока. Необходимо иницилизация переменных!
    * **`firstprivate(var1, ...)`:**  Как `private`, но инициализирует локальные копии значениями из главного потока.
    * **`lastprivate(var1, ...)`:**  Как `private`, но значение из последнего выполнившегося потока копируется обратно в главную переменную. (for – запоминается значение переменной на последней итерации, for – запоминается значение переменной на последней итерации)
* **`for`:** Распараллеливает цикл `for`. Используется совместно с `parallel`:  `#pragma omp parallel for`.  Имеет ограничения:
    * Число итераций должно быть известно до начала цикла.
    * Нельзя использовать `break` внутри цикла.
    * Счетчик должен быть целым типом.
* **`sections` / `section`:**  Распараллеливает выполнение блоков кода внутри `sections`. Каждый `section` выполняется отдельным потоком.
* **`single`:**  Блок кода выполняется только одним потоком (первым, который до него дойдет).  Имеет неявный барьер в конце. Есть команда `copyprivate` для распространения значений private переменных из single блока во ве потоки. (Только для `single`)
* **`master`:**  Блок кода выполняется только главным потоком. Нет барьера. (Нет барьера ни перед, ни после - нет синхронизации)
* **`critical`:**  Задает критическую секцию.  Код внутри `critical` выполняется только одним потоком одновременно.
* **`atomic`:**  Гарантирует атомарное выполнение одной операции.  Более эффективная альтернатива `critical` для простых операций.
* **`ordered`:**  Гарантирует выполнение кода в порядке, заданном циклом, даже внутри `parallel for`.
* **`barrier`:**  Явная точка синхронизации. Потоки ждут друг друга.  Неявный барьер есть в конце `parallel`, `for`, `sections`.  Можно отменить неявный барьер командой `nowait`.
* **`reduction(op:var)`:** Выполняет операцию `op` над переменной `var` во всех потоках и объединяет результаты в главном потоке.

**Распределение итераций в циклах (schedule):**
Для for - для равномерного распределения итераций

* **`schedule(type, chunk)`:**  Управляет распределением итераций цикла между потоками.
    * **`static`:** Статическое распределение. Итерации делятся на блоки размером `chunk` и распределяются между потоками до начала цикла.
    * **`dynamic`:** Динамическое распределение. Блоки размером `chunk` распределяются по мере освобождения потоков.
    * **`guided`:**  Размер блоков уменьшается по мере выполнения цикла.
    * **`runtime`:** Тип распределения определяется переменной окружения `OMP_SCHEDULE`.


**threadprivate:**

* Позволяет объявить глобальную переменную, которая будет иметь отдельную копию для каждого потока.
* **`copyin`:** Копирует значение `threadprivate` переменной из главного потока в остальные.

**Блокировки (мьютексы):**

Мьютекс (mutual exclusion — «взаимное исключение») — это механизм синхронизации, который используется для управления доступом к общему ресурсу в среде многопоточного программирования.

Бинарная переменная – два состояния:

- Блокированный
- Разблокированный

*Использование*

- При доступе – заблокировать мьютекс
  - Если уже заблокирован, тогда ждем пока не разблокируется
- При завершении доступа – разблокировать мьютекс
  - Разблокировать должен тот поток, который заблокирован

- omp_lock_t– тип данных мьютекса
- void omp_init_lock ( omp_lock_t *lock ) - инициализации блокировки объекта с указателем lock
- void omp_set_lock ( omp_lock_t *lock ) – установка блокировки
- void omp_unset_lock ( omp_lock_t *lock ) – разблокировка
- void omp_destroy_lock ( omp_lock_t *lock ) – гарантирует, что объект с указателем lock в данный становится не инициализированным)
- int omp_test_lock ( omp_lock_t *lock ) – попытка заблокировать объект, не прерывая выполнения потока.
  - TRUE или 1 – успешно
  - FALSE или 0– иначе

```cpp 
omp_lock_t lock;
omp_init_lock(&lock);
int a = 0;
#pragma omp parallel for shared(lock)
for (int i = 0; i < 10000; i++) {
    omp_set_lock(&lock);
    a++;
    omp_unset_lock(&lock); 
} 
omp_destroy_lock(&lock); 
cout << a; // 10000
```

**Эффективное использование OpenMP:**

* Минимизировать синхронизацию.
* Измерять время выполнения с помощью `omp_get_wtime()`.
* Балансировать нагрузку между потоками с помощью `schedule`.
* Синхронизация и создание удаление/потоков – «дорогие операции» 
* Применять синхронизацию как можно реже 
* Измерение времени - Не думайте - измеряйте - omp_get_wtime begin = omp_get_wtime(); … duration = omp_get_wtime() - begin; 
* Не используйте clock() – время, затраченное всеми потоками
* Загрузка процессоров и балансировка нагрузки 
* - чтобы процессоры меньше простаивали 
    * Повышение производительности
*  Простой процессоров 
   * Синхронизация ожидания 
* Для циклов – неравномерная сложность итераций


**Автоматическое распараллеливание:**

* Компилятор может автоматически распараллеливать некоторые циклы.
* Выполняется компилятором
* Следует использовать при работающем последовательном аналоге до ручного распараллеливания 
* После автоматического распараллеливания рекомендуется провести профилирование программы 
  * При необходимости распараллеливать «вручную»

**Резюме:**

OpenMP предоставляет мощный инструментарий для распараллеливания программ.  Важно понимать принципы работы с общей памятью и механизмы синхронизации для эффективного использования OpenMP.  Необходимо минимизировать синхронизацию, балансировать нагрузку и измерять производительность для достижения наилучших результатов.

## Тема 3 - 4. MPI: Подробное руководство

MPI (Message Passing Interface) - это стандартный интерфейс для передачи сообщений между процессами, используемый для параллельного программирования, особенно на системах с распределенной памятью. 

**Цель MPI:** Обеспечить эффективный механизм обмена данными между процессами, работающими совместно над одной задачей.

**Модель программирования:** SPMD (Single Program Multiple Data) - "одна программа, разные данные".  Каждый процесс выполняет одну и ту же программу, но работает с разными данными и может следовать различным путям выполнения в зависимости от своего ранга (номера).

**Основные концепции и функции:**

**1. Инициализация и завершение:**

* **`MPI_Init(int* argc, char*** argv)`:** Инициализирует MPI среду.  `argc` и `argv` - указатели на аргументы командной строки (могут быть `NULL`). Возвращает код ошибки.
* **`MPI_Finalize()`:** Завершает работу с MPI.  Все вызовы MPI функций после `MPI_Finalize()` запрещены.  Возвращает код ошибки.

**2. Коммуникаторы:**

* **Коммуникатор:** Группа процессов, которые могут обмениваться сообщениями.
* **`MPI_COMM_WORLD`:** Предопределенный коммуникатор, включающий все запущенные процессы.
* **`MPI_Comm_size(MPI_Comm comm, int* size)`:** Возвращает количество процессов в коммуникаторе `comm` в переменную `size`.
* **`MPI_Comm_rank(MPI_Comm comm, int* rank)`:** Возвращает ранг (номер) текущего процесса within коммуникатора `comm` в переменную `rank`.
* **`MPI_Comm_split(MPI_Comm comm, int color, int key, MPI_Comm* newcomm)`:** Создает новый коммуникатор `newcomm` путем разделения процессов в  `comm` на основе  `color`  и  `key`. Процессы с одинаковым `color` попадают в один коммуникатор. `key` определяет порядок рангов в новом коммуникаторе.
* **`MPI_Comm_free(MPI_Comm* comm)`:** Освобождает коммуникатор `comm`.
* **`MPI_Comm_dup(MPI_Comm comm, MPI_Comm *newcomm)`:** Создает дубликат коммуникатора `comm` в `newcomm`.

**3. Группы:**

* **Группа:** Упорядоченное множество рангов процессов.  Используется для создания новых коммуникаторов.
* **`MPI_Comm_group(MPI_Comm comm, MPI_Group* group)`:** Возвращает группу, связанную с коммуникатором `comm`.
* **`MPI_Group_free(MPI_Group* group)`:** Освобождает группу `group`.
* Функции для операций над группами (объединение, пересечение, разность и т.д. - смотрите документацию).
* **`MPI_Comm_create(MPI_Comm comm, MPI_Group group, MPI_Comm* newcomm)`:** Создает новый коммуникатор  `newcomm`  из группы `group`.

**4. Точечный обмен сообщениями:**

* **`MPI_Send(void* buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)`:** Отправляет `count` элементов типа `datatype` из буфера `buf` процессу с рангом `dest` в коммуникаторе `comm` с тегом `tag`.
* **`MPI_Recv(void* buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status *status)`:** Принимает сообщение в буфер `buf`.  `count`, `datatype`, `source`, `tag` и `comm` работают аналогично `MPI_Send`.  `status` содержит информацию о принятом сообщении (например, фактическое количество принятых элементов, источник и тег).
* **Неблокирующие версии:** `MPI_Isend` и `MPI_Irecv` позволяют продолжить выполнение программы без ожидания завершения операции.  `MPI_Wait` и `MPI_Test` используются для проверки и ожидания завершения неблокирующих операций.
* **Варианты `MPI_Send`:** `MPI_Rsend` (негарантированная отправка), `MPI_Ssend` (синхронная отправка), `MPI_Bsend` (буферизованная отправка).

**5. Коллективные операции:**

* **`MPI_Bcast(void* buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm)`:**  Распространяет данные из буфера процесса `root` всем процессам в коммуникаторе `comm`.
* **`MPI_Scatter(void* sendbuf, int sendcount, MPI_Datatype sendtype, void* recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm)`:**  Разделяет данные из буфера `sendbuf` процесса `root` и рассылает части другим процессам.
* **`MPI_Gather(void* sendbuf, int sendcount, MPI_Datatype sendtype, void* recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm)`:** Собирает данные от всех процессов в буфер процесса `root`.
* **`MPI_Allgather(void* sendbuf, int sendcount, MPI_Datatype sendtype, void* recvbuf, int recvcount, MPI_Datatype recvtype, MPI_Comm comm)`:** Аналогично `MPI_Gather`, но данные собираются у всех процессов.
* **`MPI_Reduce(void* sendbuf, void* recvbuf, int count, MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm)`:** Выполняет редуктивную операцию (например, сумма, максимум, минимум) над данными от всех процессов и помещает результат в буфер процесса `root`.
* **`MPI_Allreduce(void* sendbuf, void* recvbuf, int count, MPI_Datatype datatype, MPI_Op op, MPI_Comm comm)`:** Аналогично  `MPI_Reduce`, но результат доступен всем процессам.
* **`MPI_Barrier(MPI_Comm comm)`:**  Синхронизирует все процессы в коммуникаторе `comm`.

**6. Производные типы данных:**

* Позволяют создавать пользовательские типы данных для передачи сложных структур.
* `MPI_Type_contiguous`, `MPI_Type_vector`, `MPI_Type_hvector`, `MPI_Type_indexed`, `MPI_Type_hindexed`, `MPI_Type_struct`.


**7. Измерение времени:**

* **`MPI_Wtime()`:** Возвращает текущее время. Используется для измерения времени выполнения участков кода.


## Тема 5. Основы архитектуры ЭВМ и выполнения программ

**Лекция** посвящена основам функционирования ЭВМ и выполнению программ процессором. Рассматривается упрощенная модель: одна программа на одном процессоре без операционной системы.

**Литература:** Таненбаум – Архитектура компьютера (6-е издание).

**Архитектура компьютера (общая картина):**

* **Архитектура фон Неймана:**
    * Центральный процессор (ЦП)
    * Память (данные и программа хранятся вместе)
    * Обращение к памяти по адресу
    * Шина (данных, адреса, управления)

* **Программа и процесс:**
    * Программа – последовательность команд.
    * Процесс – исполняемая программа.

**Архитектуры компьютеров (по памяти):**

* **Архитектура фон Неймана (Принстонская):** Программа и данные хранятся в общей памяти.
* **Гарвардская архитектура:**  Программа и данные хранятся в отдельных областях памяти.

**Регистры:**

ЦП использует регистры для вычислений.  Существуют регистры общего назначения и специальные регистры.

**Выполнение программ (упрощенно):**

* Программа выполняется пошагово, изменяя состояние памяти (без учета операций ввода/вывода).
* ЦП исполняет программу, память хранит информацию.
* Обращение к памяти по адресу. Указатель команд (IP - Instruction Pointer) указывает на следующую команду.
* Команда перехода изменяет значение IP.

**Цикл выполнения команд (упрощенно):**

* Чтение из памяти (инструкции и данные).
* Исполнение.
* Запись в память.

**Типы команд (упрощенно):**

* Вычисление (например, сложение, вычитание).
* Переход (изменение порядка выполнения команд).

**Формат команд (упрощенно):**

`команда out(r/m) in1(r/m/c) in2(r/m/c)`

* `r` – регистр.
* `m` – память.
* `c` – константа.

**Пример:** `add ebp 04 05` (сложение значения из памяти по адресу 04 с значением 05 и запись результата в регистр ebp),  `sub 05 ebp 01` (вычитание из значения 05 значения регистра ebp и запись результата в ячейку памяти по адресу 01).


**Взаимодействие с памятью (пример):**

* `i++`: Для выполнения этой операции необходимо знать адрес переменной `i` в памяти.

**Хранение переменных:**

* Глобальные переменные имеют фиксированные адреса.

**Вызов функции и хранение локальных переменных:**

* **Стек вызовов:**
    * Хранит локальные переменные, временные результаты, аргументы функций.
    * EBP (указатель на базу фрейма) и ESP (указатель на вершину стека) используются для управления стеком.
    * Фрейм стека – область памяти, выделенная для функции. Размер фрейма фиксирован для каждой функции.
    * Адреса локальных переменных и параметров рассчитываются относительно EBP.
    * «Мусор» в неинициализированных переменных –  случайные значения, оставшиеся в памяти.
    * Удаление переменных со стека происходит быстро путем изменения ESP.
    * Стек также хранит адрес возврата из функции.

**Хранение результатов выполнения:**

* Глобальные и статические переменные хранятся в выделенной области памяти.
* Стек хранит временные данные.
* **Куча:** динамически выделяемая память для промежуточных результатов, которые должны сохраняться между вызовами функций.

**Организация памяти:**

* Программа, глобальные и статические переменные, стек и куча располагаются в разных областях памяти.
* Глобальные переменные инициализируются нулями.

**Массивы и указатели:**

* Передача аргументов в функции всегда происходит по значению.
* «Значение» указателя – адрес в памяти.
* Массивы имеют фиксированный размер (в момент объявления).
* Передача параметров: по значению, по указателю, по ссылке.
* Ссылка – «синтаксический сахар» для указателя.
* В C++99 (и более поздних стандартах) можно использовать динамические массивы.
* Атака переполнения буфера –  запись данных за пределы выделенной памяти.
* Нельзя передать указатель как массив (размеры неизвестны).

**Структуры и классы:**

* **C++:**
    * Поля структуры/класса хранятся последовательно в памяти.
    * Объекты класса могут располагаться в стеке или куче.
    * Срезка – потеря части информации при приведении объекта производного класса к типу базового класса.
    * Деструкторы вызываются при уничтожении объекта.
    * Последовательность вызова конструкторов определяется порядком объявления членов класса.

* **C#:**
    * Структура (ValueType, sealed) – хранится в стеке.
    * Класс (ссылочный тип) – хранится в куче.
    * Boxing/unboxing – преобразование между типами значений и ссылочными типами.

**Обращения к внешним устройствам:**

* **Без прерываний:**  процессор ожидает завершения операции.
* **Прерывания и исключения:**  асинхронные события, которые прерывают нормальное выполнение программы.
* **Обработчик прерываний/исключений:**  специальная функция, которая выполняется в ответ на прерывание/исключение.
* **Виды прерываний:**
    * Аппаратные (например, сигнал от устройства).
    * Программные (например, деление на ноль).
* **DMA (Direct Memory Access):** прямой доступ к памяти, позволяющий устройствам обмениваться данными с памятью без участия процессора.

**Резюме:**

* Программа и данные хранятся в памяти (архитектура фон Неймана).
* Стек хранит локальные и временные переменные.
* Куча хранит промежуточные результаты, которые должны сохраняться между вызовами функций.

## Тема 6. Организация компьютера

**Лекция 06 – Организация компьютера**

**О лекции:**

* Рассматривается однопроцессорный компьютер.
* **Цель:**
    * Изучить выполнение программы процессором.
    * Изучить организацию компьютера.
    * Научиться писать эффективные программы.

**Литература:**

* Таненбаум – Архитектура компьютера (6-е издание).
* Большинство изображений взято оттуда.

**Организация компьютера (общая картина):**

Компьютерная организация представляет собой многоуровневую структуру:

* **Уровень языка прикладных программистов:** Языки высокого уровня.
* **Ассемблер:** Язык низкого уровня.
* **Уровень ОС:** Архитектура + системные вызовы.
* **Архитектура:** Логическое представление компьютера с точки зрения программиста.  Набор команд (ISA), организация памяти и т.д.
* **Микроархитектура (МА):** Как архитектура реализована аппаратно.
* **Цифровой-логический уровень:**  Аппаратное обеспечение (АО).

**Архитектура:**

* **Набор команд (ISA):**  Компиляция в программу уровня ISA. ISA - связующее звено между компиляторами/ПО и АО. Производительность эквивалентных машин с разными ISA может отличаться на 25%.  Уровень МА может быть виден лишь частично (например, поддерживается ли суперскалярность?).
* **Организация памяти.**

**Архитектура и микроархитектура:**

* Уровень архитектуры добавлен для:
    * Легкой замены микроархитектуры.
    * Использования одного набора команд для разных компьютеров.
* Аналогия с ООП:  Архитектура – интерфейс, Микроархитектура – реализация.
* Примеры архитектур: x86, x64.

**Организация компьютерных систем:**

* **ЦП:** Выполняет программы, находящиеся в памяти. Вызывает команды из памяти, декодирует и выполняет их последовательно.  Использует внутреннюю шину для связи компонентов ЦП и внешнюю шину для связи с памятью и устройствами ввода-вывода.
* **Память:** Хранит программы и данные.
* **Устройства ввода-вывода (УВВ).**

**ЦП:**

* **Блок управления:** Вызывает команды из памяти и определяет их тип.
* **АЛУ:** Выполняет арифметические и логические операции.
* **Регистры:** Быстрая память небольшого объема для хранения промежуточных результатов и некоторых управляющих команд. Операции с регистрами быстрые. Размер регистров = разрядность компьютера = длина машинного слова.
* **Счетчик команд (указатель команд).**
* **Регистр команд:** Хранит текущую команду.


**Основная (оперативная) память (ОП):**

* Хранит программы и данные.
* Состоит из ячеек с адресами. Ячейка – минимальная адресуемая единица.
* **Кэш-память:** Быстрая память небольшого объема для хранения часто используемых данных. Доступ к кэшу быстрее, чем к ОП. Иерархия кэш-памяти (L1-I, L1-D, L2, L3).

**Вспомогательная (внешняя) память:**

* Больший объем, чем у ОП.
* Иерархическая структура памяти.

**Иерархическая структура памяти:**

* Сверху вниз:
    * Увеличивается время доступа (регистры < кэш < ОЗУ < SSD < HDD).
    * Растет объем памяти (регистры < кэш < ОЗУ < HDD).
    * Уменьшается стоимость за бит.

**Элементы компьютера:**

* **ОЗУ (DRAM):** Динамическая память с произвольным доступом.  SIMM/DIMM модули. Организована в банки для параллельного доступа.
* **Упорядочение байтов:** Big endian и little endian.  Проблемы возникают при передаче данных между компьютерами с разным упорядочением.

**Магнитные (жесткие) диски:**

* Механическое устройство: диск и головка.
* **Внешний интерфейс:** Контроллер управляет диском (перемещение головки, исправление ошибок, буферизация, кэширование). IDE интерфейс.

**Производительность диска:**

* **Позиционирование:** Перемещение головки.
* **Время ожидания сектора:** Вращение диска.
* **Время передачи сектора.**

**SCSI-диски:**

* Аналогичное жестким дискам внутреннее устройство, но другой интерфейс (SCSI) и шина (более высокая скорость).
* Используются в серверах (RAID).
* Позволяют работать всем устройствам одновременно.


**RAID-массивы:**

* Повышают производительность и надежность хранения данных.
* ОС видит RAID-массив как один диск.
* Используются SCSI диски.

**SSD-диски (твердотельные):**

* Основаны на флэш-памяти.
* **Плюсы:** Высокая скорость, низкое энергопотребление, нет времени поиска.
* **Минусы:** Стоимость, ограниченный ресурс перезаписи.


**Эффективное использование внешней памяти:**

* Предпочтительнее SSD.
* Использование RAID.
* Для HDD: чтение/запись в соседние дорожки, дефрагментация, избегать параллельного использования.

**Шины:**

* Соединяют компоненты компьютерной системы.
* УВВ содержит контроллер, который управляет устройством и доступом к шине.
* **DMA (прямой доступ к памяти):** Запись в память без участия ЦП.
* **Современные шины:**  Выделенная шина между ЦП и ОП, PCI и PCIe для УВВ.


**PCI:**

* Параллельная передача данных.
* Ограниченная скорость из-за расфазировки.


**PCIe:**

* Последовательная передача данных (пакеты).
* Высокая скорость.
* Использует линии (lanes).


**Тактовый генератор:**

* Синхронизирует устройства.
* Параметры: частота, время такта.
* Каждое устройство имеет множитель.

**Цифровой-логический уровень:**

* Аппаратное обеспечение.
* Состоит из вентилей (транзисторы).
* Вычисление И, ИЛИ.
* Память – группа вентилей.

**Вентили:**

* Транзисторы – быстрые переключатели.
* Простейшие вентили: НЕ, НЕ-И, НЕ-ИЛИ, И, ИЛИ.
* Полнота: любая булева функция может быть построена из И, ИЛИ, НЕ.


**Микросхемы (МС)/интегральные схемы (ИС):**

* Модули с вентилями.


**Виды схем:**

* **Комбинаторные:** Выход зависит от входа.
* **Элементы памяти.**
* **Логические:** Мультиплексоры, декодеры, компараторы.
* **Арифметические:** Сумматоры, схемы сдвига.

**Сумматоры:**

* Битовые (полусумматор, полный сумматор).
* n-битовые (сумматор со сквозным переносом, сумматор с выбором переноса).


**АЛУ:**

* Состоит из одноразрядных АЛУ.


**Тактовый генератор:**

* 4 интервала: высокий сигнал, низкий сигнал, фронт, спад.

**Вентили памяти:**

* Защелки (SR-защелка, синхронные SR- и D-защелки).
* Триггеры (запускаются перепадом сигнала).


**Соединение триггеров:**

* Регистры.


**Организация памяти и МС памяти:**

* Доступ к отдельным словам.

**СОЗУ и ДОЗУ:**

* **СОЗУ (SRAM):** D-триггеры, быстрая, используется для регистров и кэша.
* **ДОЗУ (DRAM):**  Массив ячеек (транзистор + конденсатор), медленнее СОЗУ, требует обновления.


**Виды ДОЗУ:**

* Асинхронные (FPM, EDO).
* Синхронные (SDRAM, DDR, DDR2, DDR3).
* Банки – блоки памяти для параллельного доступа.

**Цоколевка ЦП:**

* **Шины:** адресные, информационные, управляющие.

**Шины и выводы ЦП:**

* Параметры, определяющие производительность: число адресных и информационных выводов.
* **Управляющие сигналы:**  управление шиной, прерывания, арбитраж шины, сигналы сопроцессора, состояние.


**Шина:**

* **Системная шина** (в первых ПК).
* **Современные ПК:** выделенная шина ЦП-ОЗУ, шины для УВВ (USB, PCI, SCSI).
* **Типы:** синхронная, асинхронная.


**Повышение производительности шины:**

* Сокращение времени цикла.
* Увеличение ширины шины данных.
* **Мультиплексные шины:**  адресные и информационные линии совмещены.


**Дополнительные управляющие сигналы:**

* **Передача блоками:** чтение нескольких слов сразу.
* **CAS (Column Address Strobe):** для чтения строки кэш-памяти.
* **Специальный цикл шины:** для чтения, изменения и записи слова без освобождения шины.



**Примеры ЦП и шин (Intel Core i7):**

* 64-разрядное n-ядерное ЦПУ.
* Кэши: L1, L2, L3.
* Шины: DDR3 (память), PCI Express (УВВ).


**Шина PCI и ее развитие:**

* ISA, PCI, PCI 2.


**PCIe:**

* Замена параллельной шины последовательными соединениями.
* Передача пакетов.

**Архитектура системы Pentium (c PCI).**

**PCIe:**

* Структура шин в Core i7 (с PCIe).

## Тема 7. Кэш-память

**Лектор:** Еникеев Р.Р.

**О лекции:**

* Рассматривается однопроцессорная система.
* **Цель:**
    * Изучить организацию кэш-памяти.
    * Научиться писать эффективные программы, учитывая особенности работы кэш-памяти.

**Литература:**

* Таненбаум – Архитектура компьютера (6-е издание)
* Богачев – Основы параллельного программирования
* Маркова, Киреев, Остапкевич, Перепелкин - Эффективное программирование современных микропроцессоров (НГТУ)
*(Большинство изображений взято из указанной литературы)*

**Организация системы памяти:**

* Организация памяти – важный аспект проектирования компьютеров.
* Время доступа к данным должно быть минимальным.
* ОЗУ работает медленнее процессора, и эта разница в скорости увеличивается.
* **Решение:** использование кэш-памяти (КП).
    * Быстрая SRAM "рядом" с процессором.
    * Хранит копии часто используемых данных.
    * Разгружает шину памяти, позволяя нескольким процессорам (в многопроцессорных системах) разделять ее без потери производительности.

**Уровни кэша:**

* L1, L2, L3
* **Расположение:**
    * L1 – внутри процессора.
    * L2 – в корпусе процессора.
    * L3 – в корпусе процессора/на материнской плате.
* Содержимое L1 дублируется в L2, содержимое L2 – в L3 (инклюзивная архитектура).

**Виды кэша:**

* Разделенная кэш-память (гарвардская архитектура): L1-I (инструкции), L1-D (данные).  Позволяет выполнять операции чтения инструкций и данных параллельно.
* Единый кэш (инструкции и данные в одном кэше).
* Специализированные кэши (например, TLB для ускорения преобразования виртуальных адресов в физические).

**(Пример системы с тремя уровнями кэша)** *(изображение из литературы)*

**Кэш-промах и кэш-попадание:**

* При запросе данных процессор обращается к контроллеру кэша.
* **Кэш-попадание:** данные есть в кэше и сразу возвращаются процессору.
* **Кэш-промах:** данных нет в кэше, запрос перенаправляется в ОЗУ.
* **Цель:** максимизировать количество кэш-попаданий, храня в кэше наиболее часто используемые данные.

**Функции контроллера кэша:**

* Загрузка/выгрузка данных из ОЗУ в КП.
* Контроль запросов процессора к памяти.
* Проверка наличия данных в кэше.
* Выдача данных или перенаправление запроса в ОЗУ.
* Обеспечение когерентности (согласованности) данных между КП и ОЗУ.

**Локализация (локальность):**

* Свойство программ по доступу к памяти.
* **Пространственная локализация:** после обращения к ячейке памяти процессор с высокой вероятностью обратится к соседним ячейкам.
    * Примеры: последовательные команды, локальные переменные функции, элементы массива.
* **Временнáя локализация:** недавно использованные данные с высокой вероятностью будут использованы снова.
    * Примеры: команды внутри цикла, счетчик цикла.
* Используется при выборе данных для вытеснения из кэша при кэш-промахе (вытесняются давно неиспользованные данные, например, по алгоритму LRU).

**Использование принципа локализации для написания эффективных программ:**

* Иерархическая память построена на принципе локальности.
* Анализируя программы, можно создавать эффективные кэши, а также писать программы, которые максимально используют локальность данных.

**Организация работы кэш-памяти:**

* ОЗУ делится на блоки фиксированного размера – **строки кэша (кэш-линии)**.
* Устанавливается соответствие между блоками ОЗУ и строками кэша.
* Строка кэша состоит из последовательных байтов (от 4 до 64).
* Каждая строка имеет уникальный номер.
* При чтении байта/слова из ОЗУ загружается вся кэш-линия.
* Возвращается процессору только запрошенное слово/байт.

**Типы кэш-памяти:**

* Прямого отображения.
* Ассоциативная.
* Множественно-ассоциативная.
* Эффективность кэширования крайне важна для производительности из-за большой разницы в скорости процессора и ОЗУ.

**Кэш-память прямого отображения (КППО):**

**(Пример структуры элемента КППО для 32-битной системы)** *(изображение из литературы)*

* Адрес памяти делится на: тег, строку, слово.
* Тег используется для идентификации блока ОЗУ, хранящегося в кэш-линии.
* Строка определяет номер строки в кэше.
* Тег+строка – уникальный номер кэш-линии.
* **Недостаток:** буксование кэша при частых обращениях к данным, отображающимся на одну и ту же строку кэша.

**Ассоциативная КП:**

* Любой блок ОЗУ может быть загружен в любую строку кэша.
* Нет буксования.
* Поиск нужной строки осуществляется параллельным сравнением тега адреса с тегами всех строк.
* Время доступа больше, чем у КППО.

**Множественно-ассоциативная КП:**

* Компромисс между КППО и ассоциативной КП.
* Кэш делится на *n* банков (множеств).  Каждый банк – это, по сути, КППО.
* *n*-путная ассоциативная КП хранит *n* строк с одинаковым номером строки (но разными тегами).
* Поиск осуществляется параллельно в пределах множества.
* Для вытеснения данных используется алгоритм LRU (Least Recently Used).

**(Схема множественно-ассоциативной КП)** *(изображение из литературы)*

**Способы записи значений из КП в ОЗУ:**

* **Сквозная запись:** немедленное обновление данных в ОЗУ.  Проще реализация, более надежно, но высокая нагрузка на шину памяти.
* **Обратная (отложенная) запись:** запись откладывается до вытеснения кэш-линии.  Меньшая нагрузка на шину, но данные в ОЗУ могут быть устаревшими.
* **Запись в ячейку, которой нет в кэше:**
    * При обратной записи используется *заполнение по записи* – данные после записи загружаются в кэш.
    * При сквозной записи данные в кэш не загружаются.
* Нет универсального "лучшего" способа.


**Характеристики КП современных процессоров:**

**(Таблица с характеристиками)** *(данные из литературы)*

**Предвыборка данных:**

* Механизм уменьшения простоев процессора из-за ожидания данных из ОЗУ.
* Загрузка данных в кэш до того, как они потребуются процессору.


**Аппаратная и программная предвыборка данных:**

* **Программная:** программист/компилятор явно вставляет команды предвыборки.
* **Аппаратная:** выполняется контроллером кэша автоматически.
* Аппаратная предвыборка может ошибаться и вытеснять полезные данные.
* Эффективна для предсказуемых паттернов доступа к памяти (например, последовательный обход массива).


**(Пример предвыборки данных)** *(изображение из литературы)*

**Core i7 (пример организации кэша):**

* Все кэши 8-путные ассоциативные с размером кэш-линии 64 байта.
* L1-D использует сквозную запись.
* Два блока аппаратной предвыборки.

**Использование особенностей КП для повышения производительности:**

* **Структуры данных в C++:**
    * Массивы и матрицы: элементы хранятся последовательно.
    * Матрицы в C++ хранятся построчно (в Fortran – постолбцово).

**Примеры:**

* Обход элементов матрицы.
* Перемножение матриц.
* Транспонирование матрицы.


**Обход/обработка элементов матрицы:**

* **Задача:** обход матрицы (суммирование, поиск и т.д.).
* **Способы:**
    * Построчно (более эффективно с точки зрения кэша).
    * Постолбцово (может привести к буксованию кэша).

**(Примеры обхода матрицы и анализа кэш-промахов)** *(подробное описание с учетом размера кэш-линии, ассоциативности и т.д.)*

**Перемножение матриц:**

* Различные алгоритмы:
    * По строкам матрицы C (стандартный).
    * По столбцам матрицы C.
    * По блокам MxM матрицы C.
    * По блокам MxM матриц A и B.
    * С транспонированием матрицы B.

**(Подробное описание каждого алгоритма и анализ эффективности с точки зрения кэша)**


**False Sharing:**

**(Описание проблемы ложного совместного использования данных)**

**Резюме:**

* КП значительно ускоряет доступ к памяти.
* КП основана на принципе локальности.
* При написании программ необходимо учитывать особенности работы кэша для достижения максимальной производительности.


## Тема 8. Повышение производительности процессора

**О лекции:**

* Рассматривается однопроцессорный компьютер.
* **Цель:** изучить архитектуру современных ЦП для написания эффективных программ.
* **Литература:**
    * Таненбаум – Архитектура компьютера (6-е издание)
    * Богачев – Основы параллельного программирования
    * Маркова, Киреев, Остапкевич, Перепелкин - Эффективное программирование современных микропроцессоров (НГТУ)
    * Большинство изображений взято из указанной литературы.

**Архитектура и микроархитектура:**

* **Архитектура:** логическое представление компьютера с точки зрения программиста (организация памяти, набор команд, форматы данных, способы адресации и т.д.). Пример: x86-64.
* **Микроархитектура:** аппаратная реализация архитектуры. Меняется часто, в отличие от архитектуры.

**Методы повышения производительности ЦП:**

* **"Простые" решения:**
    * Уменьшение элементной базы (ограничения: скорость света, квантовая физика).
    * Повышение тактовой частоты (недостаток: нагревание).
* Усовершенствование микроархитектуры.
* Параллелизм на уровне процессоров.

**Развитие микропрограммирования:**

* **Начальные этапы:** два уровня – уровень архитектуры набора команд (ISA) и цифровой логический уровень. Недостаток: все команды – арифметико-логические операции (АО).
* **Изобретение микропрограммирования:** интерпретация программ, упрощение АО, упрощение расширения ISA.
* **Закат микропрограммирования:** низкая скорость работы микропрограмм.

**Производительность процессоров:**

* Время цикла: T = 1/F (F – тактовая частота).
* Время на задачу: C * T * I (I – число инструкций, C – число циклов на инструкцию).

**Архитектуры процессоров:**

* RISC (Restricted Instruction Set Computer).
* CISC (Complex Instruction Set Computer).

**Архитектура CISC:**

* Цель: уменьшить I.
* Сложные инструкции внутри процессора (микрокод).
* Сложно уменьшать C и T:  C – программное декодирование инструкций, T – аппаратная сложность.
* Ориентирована на программирование на ассемблере.

**Архитектура RISC:**

* Основана на статистическом анализе преобладания простейших инструкций.
* Уменьшение C (простые инструкции) и T (упрощение процессора).
* Увеличение I компенсируется оптимизирующими компиляторами.
* Ориентирована на языки высокого уровня.

**Принципы RISC:**

* Максимум команд в секунду.
* Все команды выполняются на АО (одна инструкция на цикл).
* Одинаковый формат инструкций.
* Простое декодирование команд.
* Архитектура "чтение/запись" (STORE/LOAD).
* Много регистров.
* Использование оптимизирующего компилятора.
* ЦП Intel – гибрид CISC и RISC.

**Улучшения микроархитектуры:**

* **Ускорение доступа к памяти:** предвыборка команд и данных, кэш-память, виртуальная память, большой регистровый файл,  высокоскоростные шины.
* **Ускорение выполнения команд:** упрощение набора команд, конвейеризация.

**Повышение производительности ЦП:**

* **Параллелизм:**
    * На уровне команд (временной): запуск большого количества команд в секунду.
    * На уровне процессоров (пространственный): одновременная работа нескольких ЦП над одной задачей.

**Стадии выполнения команд:**

выборка -> декодирование -> загрузка операндов -> исполнение -> запись результатов.

**Конвейерный процессор:**

* Конвейер: несколько последовательно соединенных устройств (ступеней).
* Развитие концепции предвыборки.
* Временной параллелизм.

**Конвейеры в RISC и CISC:**

* RISC: все инструкции исполняются за один цикл.
* CISC: сложность конвейеризации из-за нерегулярного потока инструкций и переменного времени исполнения инструкций. Конвейеризация на уровне микрокоманд.

**Характеристики конвейера:**

* **Пропускная способность:** число команд, выполняемых в единицу времени.
* **Латентность:** время между попаданием команды на конвейер и получением результата.

**Производительность конвейера:**

* Время разгона конвейера.
* N ступеней увеличивают производительность в N раз (идеально).
* Обращение к памяти: кэш-память и предвыборка инструкций.

**Факторы, влияющие на производительность конвейера:**

* Зависимость по данным.
* Зависимость по управлению.
* Зависимость по ресурсам.


**Зависимость по данным:**

* Следующей команде нужно значение, которое еще не записано предыдущей командой.
* Ожидание ("пузырек").

**Устранение задержек из-за зависимостей по данным:**

1. Пересылка данных между ступенями.
2. Переупорядочивание инструкций (компилятором или ЦП).
3. Дополнительные решения: таблица регистров, переименование регистров.

**Зависимость по управлению:**

* Вызвана командой перехода.
* Сброс конвейера и "пузырек".

**Устранение задержек из-за зависимостей по управлению:**

* Обнаружение и предсказание переходов (статические и динамические методы).

**Статические методы предсказания переходов:**

* Используют информацию из кода (компилятор).
* Однозначный вывод о переходе на стадии декодирования.
* Способы: профилирование.

**Динамические методы предсказания переходов:**

* Основаны на истории переходов во время выполнения программы.
* На стадии выборки команды.
* Реализация: специальная таблица, прогноз на основе предыдущих переходов.


**Зависимость по ресурсам:**

* Ресурсы: функциональные устройства, регистровый файл, кэш-память.
* Устранение: дублирование ресурсов, параллельный доступ, разнесение зависимых команд.

**Суперконвейерные процессоры:**

* Конвейеризация стадий конвейера.
* Каждая стадия может принимать инструкцию каждый цикл.

**Двойные конвейеры:**

* Два или более конвейера работают параллельно.
* Требует более широкий доступ к памяти.

**Суперскалярные процессоры:**

* Несколько инструкций выполняются параллельно (несколько функциональных блоков).

**Изменение архитектуры:**

* Усовершенствование реализации (микроархитектуры): повышение тактовой частоты, конвейеризация.
* Изменение архитектуры: добавление команд или регистров.
* VLIW (Very Long Instruction Word): развитие RISC с параллелизмом на уровне команд, выявляемым компилятором.


**Применение знаний о конвейеризации:**

* Использование оптимизирующего компилятора: максимальная загрузка конвейера, "разворачивание" цикла, минимизация переходов.
* Использование векторных команд.
* Написание параллельных программ.


**Причины развития параллельных ЦП:**

* Параллелизм на уровне команд (5-10 кратное ускорение).
* Параллельные компьютеры (50+ кратное ускорение).

**Параллелизм на уровне процессоров:**

* Матричные компьютеры.
* Мультипроцессоры (МП).
* Мультикомпьютеры (МК).

**Архитектура Флинна:**

* SISD (Single Instruction Single Data): последовательный, одноядерный конвейер.
* MISD (Multiple Instruction Single Data): конвейер?
* SIMD (Single Instruction Multiple Data): матричные, векторные процессоры.
* MIMD (Multiple Instruction Multiple Data): МП, МК.


**Матричные компьютеры:**

* Одинаковые вычисления с разными данными.
* Матричные/SIMD процессоры: параллельная обработка.
* Векторные процессоры: расширение ЦП, векторный регистр (набор регистров, загружаемых одной командой).

**SIMD процессоры:**

* Современные GPU.
* Хорошо подходят для обработки графики.

**Векторные процессоры:**

* Похожи на SIMD, но операции выполняются в одном блоке с конвейерной структурой,  в отличие от SIMD, где количество устройств равно количеству элементов в массиве.
* Пример: SSE команды (Streaming SIMD Extension) в Intel Core.

**Мультипроцессоры (МП):**

* Несколько параллельных процессоров с доступом к общей памяти.
* Требуется согласование работы с помощью ПО.
* Преимущества: легкая работа с общей памятью.
* Недостатки: конфликты при обращении к шине, необходимость локальной памяти и кэширования.


**Сложность проектирования МП и МК:**

* МП (<=256): относительно просто.
* МП (>256): сложно связать все ЦП с общей памятью (сильная связанность).
* МК: проще разрабатывать (слабая связанность), дешевле.


**Мультикомпьютеры (МК):**

* Процессоры общаются через сообщения.
* Различные топологии сети.
* Пример: Blue Gene/P (до 250 000 процессоров).

**Гибридные системы:**

* Сочетают достоинства МП (проще программировать) и МК (проще конструировать).
* Иллюзия общей памяти.

**Применение знаний о конвейеризации (продолжение):**

* Использование векторных команд.
* Написание параллельных программ для МП/МК.

**Развитие архитектуры x86 и ЦП Intel:**

* **Главный принцип:** обратная совместимость.
* **80486 (1989):** кэш-память, 1 конвейер, поддержка МП.
* **Pentium (1993):** два конвейера, команды MMX (обработка мультимедиа).
* **Pentium Pro (1995):** до 5 команд одновременно, двухуровневая кэш-память.
* **Pentium II (1997):** MMX и большой кэш на одной микросхеме.
* **Pentium III (1999):** команды SSE.
* **Pentium 4 (2000):** гиперпоточность, дополнительные SSE команды.
* **Core 2 Duo:** двухъядерный.
* **Core i7:** каждое ядро с L1 и L2 кэшем + общий L3 кэш.


**Микроархитектура Core i7:**

* 8 регистров на ядро.
* Основано на RISC-ядре с развитой конвейеризацией и поддержкой CISC-команд.
* Команды -> микрооперации -> кэширование -> конвейер с несколькими АЛУ.
* Sandy Bridge: AVX (128-разрядные векторные операции).
* Блок пересортировки результатов команд.


**Краткие итоги:**

Современные ЦП используют параллелизм на уровне команд (конвейеризация) и на уровне процессоров (МП/МК).


**(Вторая часть лекции)**

**Прогнозирование переходов:**

* **Виды переходов:** безусловные и условные (if/else).

**Безусловные переходы:**

* Сложность: декодирование на второй ступени конвейера.
* Слот отсрочки: команда после перехода (компилятор пытается найти полезную команду или NOP).

**Условные переходы:**

* Больший слот отсрочки.
* Прогнозирование переходов для избежания простоя конвейера.

**Способы прогнозирования:**

* Предположение о выполнении переходов назад (циклы) и невыполнении переходов вперёд.
* Отмена выполненных команд при неправильном прогнозе.


**Способы отмены выполненных команд:**

* Выполнение с записью изменений во временные регистры и копирование в основные при правильном прогнозе.
* Сохранение резервной копии значений регистров.


**Базовые блоки:**

* Линейная последовательность команд без переходов.
* Переупорядочивание команд внутри ББ.
* Проблема: короткие ББ ограничивают параллелизм.
* Решение: переупорядочивание команд из разных ББ.


**Спекулятивное исполнение:**

* Подъём: перемещение кода вверх (LOAD).
* Выполнение команды до того, как станет известно, нужна ли она.
* Поддержка компилятора и АО.


**Проблемы спекулятивного исполнения:**

* Отменяемость спекулятивных команд (подмена регистров).
* Исключения спекулятивных команд (бит отравления регистра).


**Параллелизм на разных уровнях:**

* Низкий: конвейеризация, суперскалярная архитектура.
* Удлинение слов в командах.
* Сопроцессоры.
* Объединение ЦП (МП, МК, GRID).


**Внутрипроцессорный параллелизм:**

* Уплотнение операций во времени.
* Параллелизм на уровне памяти (VLIW).


**VLIW (Very Long Instruction Word):**

* ЦП со сверхдлинным командным словом.
* n функциональных блоков -> n операций, n операндов.
* Ответственность на компиляторе.


**Компилятор для VLIW:**

* Упрощенное АО.
* Гибкость планирования команд.


**Недостатки VLIW:**

* Пустые операции.
* Сложность изменения архитектуры.


**Команды VLIW:**

* Инструкции для всех функциональных блоков в одной команде.
* Маркеры.


**Проблема IA-32:**

* Множество транзисторов Core i7 используются для преобразования CISC в RISC, разрешения конфликтов, прогнозирования переходов.


**Развитие архитектуры компьютеров:**

* Перенос нагрузки с исполнения на компиляцию.
* EPIC (Explicitly Parallel Instruction Computing): вычисления с явным параллелизмом команд (Itanium).


**Модель IA-64 – EPIC (Itanium):**

* Сокращение обращений к памяти.
* Планирование команд.
* Сокращение условных переходов (предикация).
* Спекулятивная загрузка.

**Спекулятивная загрузка:**

* Загрузка операндов заранее (даже если не нужны).
* LOAD перед другими командами.
* CHECK проверяет загрузку данных.

**Сокращение числа обращений к памяти:**

* Работа с памятью – узкое место.
* Обращение к памяти в фоновом режиме.

**Планирование команд:**

* Компилятор планирует обработку команд в функциональных блоках.
* Группы команд без конфликтов.
* ЦП может начать следующую группу до завершения предыдущей.
* Порядок команд в группе не важен.
* Нарушение правил приводит к неопределенному поведению.

**Предикация:**

* IA-32: безусловное выполнение команд.
* Предикатная архитектура: команды содержат условия выполнения.
* Избавление от условных переходов.
* Все команды – предикатные, выполнение и сохранение результатов определяется условием.

**Внутрипроцессорная многопоточность:**

* ЦП управляет несколькими программными потоками.
* Переключение между потоками при блокировке.

**Однокристальные МП:**

* Типы: гомогенные (одинаковые процессоры) и гетерогенные (разные процессоры).

**Гомогенные однокристальные МП:**

* >1 процессора на кристалле.
* Виды: с двумя конвейерами, с двумя ядрами.
* Пример: Core i7.

**Core i7:**

* Кольцевая шина для перемещения запросов к памяти и данных между кэшами и процессорами.
* Когерентность кэшей и памяти.

**Гетерогенные однокристальные МП:**

* Применение: аудиовизуальная техника, сотовые телефоны.
* Решение задач реального времени на дешевых процессорах.
* Пример схемы взаимодействия: CoreConnect.

**CoreConnect:**

* Шина процессора: высокоскоростная синхронная конвейеризованная шина (до 23,4 Гбит/с).
* Периферийная шина: для низкоскоростных устройств.
* Шина регистров устройств.

**Сопроцессоры:**

* Специализированный ЦП (Ввод/Вывод, графика, операции с плавающей точкой, DMA).
* Взаимодействие: ЦП передает команды или сопроцессор действует независимо.
* Применение: сетевая поддержка, обработка мультимедиа, криптография.

**Сети:**

* Устройства: компьютеры, промежуточные устройства, серверы.
* Рост скорости сетей требует аппаратной обработки пакетов.

**Аппаратная обработка пакетов:**

* ASIC (долгое проектирование, сложность изменений).
* FPGA (быстрое производство, перепрограммируемые, но сложные, дорогие и медленные).
* Сетевые процессоры (обработка в реальном времени).

**Сетевой процессор:**

* Множество PPE-контроллеров с высокой степенью параллелизма.
* Идентичные контроллеры (обработка пакета целиком) или конвейерная обработка.

**GPU:**

* Обработка графики высокого разрешения.
* ~512 ядер (SIMD).
* GPGPU (NVIDIA CUDA).

**NVIDIA Fermi:**

* 16 потоковых мультипроцессоров (SM) с общим L2 кэшем.
* Каждый SM: собственный L1 кэш, 32 ядра CUDA.
* SIMD: каждый SM выбирает и декодирует одну команду за цикл.

**Криптопроцессоры:**

* Криптография требует объемных вычислений.

**МП (SMP):**

* SMP (Symmetric MultiProcessor): симметричный МП с общей памятью.
* Единое адресное пространство (LOAD/STORE).
* Одна копия ОС.
* Одна карта страниц памяти и таблица процессов.

**МК:**

* Распределенная память.
* Каждый ЦП: своя ОС, отдельное адресное пространство.
* Взаимодействие: сообщения (SEND/RECEIVE).
* Синоним: NORMA (No Remote Memory Access).

**Пример МК:**

* Обмен данными через сообщения и блокировку.

**Написание программ для МК:**

* Сложность: распределение и размещение данных.

**Гибридные системы:**

* Сочетание достоинств МП и МК.
* Общая память в МК (аппаратная или программная реализация, DSM - Distributed Shared Memory).

**Уровни реализации общей памяти:**

* Аппаратная.
* Программная (Linda, Orca).

**Проектирование МК:**

* Масштабируемость: эффективная работа при добавлении новых ЦП.

**Категории МК:**

* MPP (Massively Parallel Processor): дорогие суперкомпьютеры с большим количеством ЦП и высокоскоростной сетью.
* COW (Cluster Of Workstations), NOW (Network Of Workstations), кластеры: связанные ПК (дешевле MPP).

**Характеристика MPP:**

* Стандартные ЦП.
* Высокопроизводительная сеть.
* Большой объем памяти.
* Отказоустойчивость.

**IBM BlueGene:**

* BlueGene/L (2001).
* BlueGene/P (2007): 65536 ЦП, 167 терафлопс/с; (2009): 294912 ЦП, 1 петафлопс/с.

**ЦП BlueGene/P:**

* 4-ядерный PowerPC 450 (850 МГц) с поддержкой SIMD.

**Кэш-память BlueGene:**

* L1 промах/L2 попадание: 11 тактов.
* L2 промах/L3 попадание: 28 тактов.
* Доступ к ОЗУ: 75 тактов.

**Кластер:**

* Сотни/тысячи связанных ПК.
* Виды: централизованные (в одной комнате) и децентрализованные.

**Кластер Google:**

* Высокоскоростная сеть (оптоволокно, до 2,488 Гбит/с).
* Распределение данных между компьютерами.
* Характеристики компьютеров: Pentium 2 ГГц, 4 ГБ ОЗУ, 2 ТБ HDD, Ethernet.
